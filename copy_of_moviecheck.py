# -*- coding: utf-8 -*-
"""Copy of moviecheck.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qUxHpMD3BmjlS_p6lDVGgFCUb5iQSXX1

Submission Project</br>
Proyek Pertama : Membuat Model NLP dengan TensorFlow</br> </br>

Data profile </br>
Nama : Handerson Loriano</br>
Email : hadezbladez@gmail.com
"""

# lib import
import pandas as pd
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
import tensorflow as tf


from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt

df = pd.read_csv('/content/all-weeks-global.csv')
df = df.drop(columns=["week","weekly_rank","season_title","weekly_hours_viewed","cumulative_weeks_in_top_10"])
df.head(100)

category = pd.get_dummies(df.category)
df_baru = pd.concat([df, category], axis=1)
df_baru = df_baru.drop(columns='category')
df_baru

description = df_baru['show_title'].values
label = df_baru[["Films (English)",	"Films (Non-English)", "TV (English)",	"TV (Non-English)"]].values

description_latih, description_test, label_latih, label_test = train_test_split(description, label, test_size=0.2)

tokenizer = Tokenizer(num_words=225, oov_token='<oov>')
tokenizer.fit_on_texts(description_latih)
tokenizer.fit_on_texts(description_test)

sekuens_latih = tokenizer.texts_to_sequences(description_latih)
sekuens_test = tokenizer.texts_to_sequences(description_test)

padded_latih = pad_sequences(sekuens_latih, padding='post', maxlen=23, truncating='post')
padded_test = pad_sequences(sekuens_test, padding='post', maxlen=23, truncating='post')

model = tf.keras.Sequential([
    tf.keras.layers.Embedding(input_dim=225, output_dim=32),
    tf.keras.layers.Dense(4096, activation='relu'),
    tf.keras.layers.LSTM(128),
    tf.keras.layers.Dense(1024, activation='relu'),
    tf.keras.layers.Dropout(0.31),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dropout(0.1),
    tf.keras.layers.Dense(4, activation='softmax')
])
model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])
num_epochs = 619

class myCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('val_accuracy') > 0.75):
      print("\nVal Akurasi telah mencapai >75%!")
      self.model.stop_training = True
mmcallbacks = myCallback()

history = model.fit(padded_latih, label_latih, epochs=num_epochs, callbacks=[mmcallbacks],
                    validation_data=(padded_test, label_test), verbose=2)

#plot loss
plt.plot(history.history['loss'])
plt.title('Model loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train'], loc='upper right')
plt.show()

#plot accuracy
plt.plot(history.history['accuracy'])
plt.title('Model accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train'], loc='lower right')
plt.show()

print(tokenizer.word_index)
print(tokenizer.texts_to_sequences(['As someone']))